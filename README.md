# ğŸ›’ Supermarket Sales Data Pipeline

## ğŸ“Œ Project Overview

This project demonstrates the design and implementation of an end-to-end
data pipeline that:

-   Extracts sales data programmatically from Kaggle using the Kaggle API
-   Transforms it into dimensional (star schema) format
-   Loads it into a SQLite database
-   Generates an analytical report using SQL (with joins and window functions)
-   Proposes a scalable cloud deployment architecture (GCP)

------------------------------------------------------------------------

# ğŸ—ï¸ Architecture Overview (Local Implementation)

Kaggle API
â†’ Python Extraction Script
â†’ Transformation (Star Schema)
â†’ SQLite Database
â†’ SQL Analytical Report

------------------------------------------------------------------------

# ğŸ“Š Data Modeling

## Dimension Tables

### dim_customer

-   customer_id (PK)
-   customer_type
-   gender

### dim_product

-   product_id (PK)
-   product_line
-   unit_price

## Fact Table

### fact_sales

-   sale_id (PK)
-   invoice_id
-   branch
-   city
-   date
-   time
-   payment
-   quantity
-   tax
-   sales
-   cogs
-   gross_income
-   rating
-   customer_id (FK)
-   product_id (FK)

------------------------------------------------------------------------

# ğŸš€ Setup Instructions

## 1ï¸âƒ£ Clone Repository

git clone https://github.com/dossn1994/supermarket-data-pipeline.git\
cd supermarket-data-pipeline

## 2ï¸âƒ£ Install Requirements

pip install pandas kaggle

## 3ï¸âƒ£ Configure Kaggle API

- Go to Kaggle â†’ Account â†’ Create API Token
- Move kaggle.json to:

  ~/.kaggle/kaggle.json
  chmod 600 ~/.kaggle/kaggle.json

- The dataset will be automatically downloaded when the ETL script runs.

------------------------------------------------------------------------

# â–¶ï¸ Running the Pipeline

## Step 1 --- Run ETL(Extraction + Transformation + Load)

python scripts/transform_load.py

This will:
- Automatically download dataset from Kaggle
- Create SQLite database (supermarket.db)
- Create dimension and fact tables
- Load transformed data

## Step 2 --- Run Analytical Report

python scripts/run_report.py

The report:
- Joins fact and dimension tables
- Aggregates total sales by product line
- Uses RANK() window function to rank product lines by revenue

------------------------------------------------------------------------

# â˜ï¸ Proposed Cloud Deployment Architecture (GCP)

-   Cloud Scheduler --- Trigger pipeline
-   Cloud Function --- Extract data using Kaggle API
-   Cloud Storage --- Extract data using Kaggle API
-   Dataflow / Cloud Function --- Transform data
-   BigQuery --- Data warehouse (dim + fact tables)
-   Looker Studio --- Reporting & dashboards

------------------------------------------------------------------------

# ğŸ“ Project Structure

supermarket-data-pipeline/
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ extract.py
â”‚   â”œâ”€â”€ transform_load.py
â”‚   â””â”€â”€ run_report.py
â”‚
â”œâ”€â”€ sql/
â”‚   â”œâ”€â”€ create_tables.sql
â”‚   â””â”€â”€ report.sql
â”‚
â”œâ”€â”€ data/ (auto-created, not versioned)
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

------------------------------------------------------------------------

# ğŸ‘¤ Author

Doss Napoleon
Data Engineer